<!-- Copyright (C) The IETF Trust (2014) -->
<!-- Copyright (C) The Internet Society (2014) -->

<section anchor="sec:fencing" title="Specifications of Original Layout Types">
  <t>
    This section is not normative with regards to each of the presented
    types. This document does not update the specification of either
    the block layout type (see <xref target='RFC5663' />) or the object
    layout type (see <xref target='RFC5664' />).  Nor does it update
    Section 13 of <xref target='RFC5661' />, but rather Section 12 of
    that document. In other words, it is the pNFS requirements being
    updated rather than the specification of the file layout type.
  </t>

  <section anchor="sec:fencing:files" title="File Layout Type">
    <t>
      Because the storage protocol is a subset of NFSv4.1, the semantics
      of the file layout type comes closest to the semantics of NFSv4.1
      in the absence of pNFS.  In particular, the stateid and principal
      used for I/O MUST have the same effect and be subject to the
      same validation on a data server as it would have if the I/O were
      being performed on the metadata server itself.  The same set of
      validations are applied whether pNFS is in effect or not.
    </t>

    <t>
      And while for most implementations the storage devices
      can do the following validations:

      <list style='format (%d)'>
        <t>
          client holds a valid layout,
        </t>
        <t>
          client I/O matches the layout iomode, and,
        </t>
        <t>
          client does not go out of the byte ranges,
        </t>
      </list>

      these are each presented as a "SHOULD" and not a "MUST". Actually,
      the first point is presented in <xref target='RFC5661' /> as both:

      <list style='hanging'>
        <t hangText='"MUST":'>
          in Section 13.6
          <vspace blankLines='1' />
          "As described in Section 12.5.1, a client MUST NOT send an I/O
          to a data server for which it does not hold a valid layout;
          the data server MUST reject such an I/O."
        </t>

        <t hangText='"SHOULD":'>
          in Section 13.8
          <vspace blankLines='1' />

          "The iomode need not be checked by the data servers when clients
          perform I/O.  However, the data servers SHOULD still validate
          that the client holds a valid layout and return an error if
          the client does not."
        </t>
      </list>

      It should be noted that it is just these layout specific checks
      that are optional, not the normal file access semantics. The
      storage devices MUST make all of the required access checks on
      each READ or WRITE I/O as determined by the NFSv4.1 protocol.
      If the metadata server would deny a READ or WRITE operation on a
      file due to its ACL, mode attribute, open access mode, open deny
      mode, mandatory byte-range lock state, or any other attributes
      and state, the storage device MUST also deny the READ or WRITE
      operation. Also while the NFSv4.1 protocol does not
      mandate export access checks based on the client's IP address,
      if the metadata server implements such a policy, then that counts
      as such state as outlined above.
    </t>

    <t>
      The data filehandle provided by the PUTFH operation to the data
      server provides sufficient context to enable the data server to
      ensure that for the subsequent READ or WRITE operation in the
      compound, that the client has a valid layout for the I/O being
      performed.
    </t>

    <t>
      Finally, the data server can check the stateid presented in the READ
      or WRITE operation to see if that stateid has been rejected by the
      metadata server in order to cause the I/O to be fenced. Whilst it might
      just be the open owner or lock owner on that client being fenced,
      the client should take the NFS4ERR_BAD_STATEID error code to mean
      it has been fenced from the file and contact the metadata server.
    </t>
  </section>

  <section anchor="sec:fencing:blocks" title="Block Layout Type">
    <t>
      With the block layout type, the storage devices are generally
      not able to enforce file-based security.  Typically, storage area
      network (SAN) disk arrays and SAN protocols provide coarse-grained
      access control mechanisms (e.g., Logical Unit Number (LUN) mapping
      and/or masking), with a target granularity of disks rather than
      individual blocks and a source granularity of individual hosts
      rather than of users or owners.  Access to block storage is
      logically at a lower layer of the I/O stack than NFSv4. Since
      NFSv4 security is not directly applicable to protocols that access
      such storage directly, Section 2.1
      <xref target='RFC5663' /> specifies that:

      <list style='hanging'>
        <t hangText=''>
          "in environments where pNFS clients cannot be trusted to enforce
          such policies, pNFS block layout types SHOULD NOT be used."
        </t>
      </list>
    </t>

    <t>
      Due to these granularity issues, the security burden
      has been shifted from the storage devices to the client.  Those
      deploying implementations of this layout type need to be sure that
      the client implementation can be trusted  This is not a new sort of
      requirement in the context of SAN protocols.  In such environments,
      the client is expected to provide block-based protection.
    </t>

    <t>
      This shift of the burden also extends to locks and
      layouts. The storage devices are not able to enforce any of these
      and the burden is pushed to the client to make the appropriate
      checks before sending I/O to the storage devices.  For example,
      the server may use a layout iomode only allowing reading to enforce
      a mandatory read-only lock,  In such cases, the client has to
      support that use by not sending WRITEs to the storage devices.
      The fundamental issue here is that the storage device is treated
      by this layout type in the same fashion as a local disk device.
      Once the client has access to the storage device, it is able to
      perform both READ and WRITE I/O to the entire storage device.
      The byte ranges in the layout, any locks, the layout iomode, etc,
      can only be enforced by the client.  Therefore, the client is
      required to provide that enforcement.
    </t>

    <t>
      In the context of fencing off of the client upon revocation
      of a layout, these limitations come into play again, i.e., the
      granularity of the fencing can only be at the host/logical-unit
      level.  Thus, if one of a client's layouts is revoked by the
      server, it will effectively revoke all of the client's layouts for
      files located on the storage units comprising the logical volume.
      This may extend to the client's layouts for files in other file
      systems.  Clients need to be prepared for such revocations and
      reacquire layouts as needed.
    </t>
  </section>

  <section anchor="sec:fencing:objects" title="Object Layout Type">
    <t>
      With the object layout type, security checks occur during the
      allocation of the layout.  The client will typically ask for
      layouts covering all of the file and may do so for either READ
      or READ/WRITE.  This enables it to do subsequent I/O operations
      without the need to obtain layouts for specific byte ranges.
      At that time, the metadata server should verify permissions against
      the layout iomode, the file mode bits or ACLs, etc. As the client
      may be acting for multiple local users, it MUST authenticate and
      authorize the user by issuing respective OPEN and ACCESS calls to
      the metadata server, similar to having NFSv4 data delegations.
    </t>

    <t>
      Upon successful authorization, the client receives within the layout
      a set of object capabilities allowing it I/O access to the specified
      objects corresponding to the requested iomode. These capabilities
      are used to enforce access control and locking semantics at the
      storage devices.  Whenever one of the following occur on the
      metadata server:

      <list style='symbols'>
        <t>
          the permissions on the object change,
        </t>
        <t>
          a conflicting mandatory byte-range lock is granted, or
        </t>
        <t>
          a layout is revoked and reassigned to another client,
        </t>
      </list>

      then the metadata server MUST change the capability version
      attribute on all objects comprising the file to in order to
      invalidate any outstanding capabilities before committing to one
      of these changes.
    </t>

    <t>
      When the metadata server wishes to fence off a client to a
      particular object, then it can use the above approach to invalidate
      the capability attribute on the given object. The client can
      be informed via the storage device that the capability has been
      rejected and is allowed to fetch a refreshed set of capabilities,
      i.e., re-acquire the layout.
    </t>
  </section>
</section>
